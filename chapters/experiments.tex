\chapter{Πειράματα}
\label{chap:experiments}

Η ενότητα αυτή εστιάζει στην πειραματική αποτίμηση των cache drivers που
υποστηρίζουν το endpoint \textit{/aggregate} της πλατφόρμας
\textit{Nostradamus}. Πρόκειται για ένα κρίσιμο microservice που εκτελεί
windowed aggregations πάνω σε χρονοσειρές αισθητήρων και λειτουργεί ως
``θερμή'' πύλη προς τη μόνιμη βάση δεδομένων. Η παραγωγική εμπειρία έχει δείξει
ότι η καθυστέρηση ανάγνωσης ή εγγραφής στην cache μεταφράζεται σχεδόν γραμμικά
σε συνολική καθυστέρηση χρηστών, επομένως η επιλογή backend (Valkey ή
Memcached) δεν είναι απλώς ζήτημα υλοποίησης αλλά παράγοντας που επηρεάζει
άμεσα τη σταθερότητα του συστήματος.

\section{Διατύπωση στόχου}

Στόχος του πειράματος είναι να μελετηθεί η συμπεριφορά δύο εναλλάξιμων cache
drivers υπό συνεχές φορτίο στο \textit{/aggregate}. Εξετάζονται τρεις
διαστάσεις: 

\begin{enumerate}
	\item \textbf{Απόδοση ανάγνωσης/εγγραφής}. Τα μονοπάτια cache hit και
		cache miss είναι συχνά ισοδύναμα σε όγκο, άρα απαιτείται
		συμμετρική αποτίμηση των read/write λειτουργιών.
	\item \textbf{Σταθερότητα υπό πίεση}. Η μέση τιμή είναι ανεπαρκής
		δείκτης για real-time IoT, επομένως δίνεται έμφαση σε υψηλά
		percentiles (P95) όπου εμφανίζονται τα πραγματικά ``outliers''
		που πλήττουν την εμπειρία χρήσης.
	\item \textbf{Συμβατότητα με περιβάλλοντα χαμηλού TTL}. Οι αισθητήρες
		δημοσιεύουν συνεχώς νέα δεδομένα με συχνές invalidations, οπότε
		ο driver πρέπει να αντιμετωπίζει εργοστασιακά workloads που
		χαρακτηρίζονται από μικρή χρονική διάρκεια ζωής εγγραφών.
\end{enumerate}

\section{Μεθοδολογία}

Δημιουργήθηκαν δύο ανεξάρτητες εκτελέσεις της πλατφόρμας: μία δεσμευμένη σε
Valkey και μία σε Memcached. Κάθε εκτέλεση τροφοδοτήθηκε με ίδιο ρυθμό
αιτημάτων, παραγόμενο από synthetic load generator που μιμείται την τυπική
δραστηριότητα αγροτικού deployment. Το cache layer υλοποιήθηκε ως εναλλάξιμη
υπηρεσία πίσω από κοινό interface, ώστε να απομονωθεί πλήρως από την
επιχειρησιακή λογική. Οι μετρήσεις συλλέχθηκαν μέσω \textit{Prometheus} και
οπτικοποιήθηκαν στο \textit{Grafana}, με focus στο P95 latency για read και
write λειτουργίες, καθώς και στην ποσοτικοποίηση των invalidations. Η
παραμετροποίηση των drivers παρέμεινε στην προεπιλεγμένη τιμή εκτός από το TTL,
που ορίστηκε στα 120~δευτερόλεπτα ώστε να προσεγγίζει το ωφέλιμο χρονικό
παράθυρο των αγρομετεωρολογικών μετρήσεων.

\section{Αποτελέσματα και συζήτηση}

Τα αποτελέσματα δείχνουν ότι το \textit{Memcached} προσφέρει σημαντικά
χαμηλότερη καθυστέρηση, περίπου $1.7\times$ κάτω από το \textit{Valkey} τόσο σε
αναγνώσεις όσο και σε εγγραφές στο P95. Το γεγονός αποδίδεται στον
μινιμαλιστικό χαρακτήρα του πρωτοκόλλου του Memcached (binary protocol με
περιορισμένο σετ εντολών), που επιτρέπει υψηλό ρυθμό I/O ακόμη και με ελαφριά
hardware αποτύπωση. Παρ' όλα αυτά, το \textit{Valkey} εμφανίζει εντυπωσιακή
σταθερότητα καθώς οι καμπύλες latency παραμένουν σφιχτά δεμένες στο baseline
του, χωρίς αιχμές ακόμη και όταν αυξάνεται το concurrency ανά pod. Η
determinism αυτή είναι κρίσιμη όταν η πλατφόρμα λειτουργεί σε περιβάλλοντα με
πολλές ταυτόχρονες συνδέσεις ή όταν απαιτούνται atomic επιχειρησιακές
λειτουργίες (π.χ. Lua scripts, complex data structures) που ο Memcached δεν
υποστηρίζει.

Ως προς την επιχειρησιακή εκμετάλλευση, το \textit{Memcached} είναι η προφανής
επιλογή για MVP υλοποιήσεις ή για workloads όπου το throughput υπερισχύει της
λειτουργικότητας. Αντίθετα, το \textit{Valkey} προτείνεται σε περιπτώσεις που η
σταθερότητα, τα advanced data types και η δυνατότητα scripting είναι
σημαντικότερα από τη μέγιστη ταχύτητα. Η αρθρωτή σχεδίαση της πλατφόρμας
επιτρέπει την εναλλαγή backend χωρίς τροποποίηση κώδικα, συνεπώς η επιλογή
μπορεί να καθοδηγείται από τις πραγματικές επιχειρησιακές απαιτήσεις κάθε
deployment.

\section{Περαιτέρω επεκτάσεις}

Τα παραπάνω αποτελούν αφετηρία. Σχεδιάζονται επιπλέον μετρήσεις που θα
καλύπτουν ρυθμό invalidations ανά driver, αποτύπωση κατανάλωσης μνήμης/CPU ανά
pod και ανάλυση της συμπεριφοράς σε workloads με προοπτική geo-distributed
replica sets. Επιπλέον, η ενσωμάτωση traces (με \textit{OpenTelemetry}) θα
βοηθήσει στο να συνδεθούν οι μετρικές cache latency με το end-to-end user
journey, κάτι που θα αποτυπώσει ακόμα πιο πειστικά την επιχειρησιακή αξία κάθε
επιλογής backend.
