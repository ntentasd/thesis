\chapter{Εργαλεία}

Τα Κυβερνο-Φυσικά Συστήματα (CPS) είναι συστήματα που αποτελούνται από ένα
φυσικό στοιχείο το οποίο ελέγχεται ή παρακολουθείται από ένα κυβερνητικό
(cyber) στοιχείο, έναν αλγόριθμο βασισμένο σε υπολογιστή. Με στόχο να
μετασχηματίσουν τον τρόπο με τον οποίο οι άνθρωποι αλληλεπιδρούν με τα μηχανικά
συστήματα, τα νέα έξυπνα CPS οδηγούν την καινοτομία σε διάφορους τομείς,
βασικός εκ των οποίων αποτελεί η γεωργία \cite{cps}. Η αρχιτεκτονική των CPS,
που αναλύθηκε στο κεφάλαιο 3, βασίζεται σε τρία βασικά επίπεδα: το φυσικό
επίπεδο (physical layer), όπου καταγράφονται και παράγονται τα δεδομένα μέσω
αισθητήρων· το επίπεδο δικτύου (network layer), που εξασφαλίζει τη μεταφορά των
δεδομένων· και το κυβερνητικό ή υπολογιστικό επίπεδο (cyber layer), όπου
λαμβάνονται αποφάσεις βάσει των εισερχόμενων δεδομένων. Η συνύπαρξη αυτών των
στρωμάτων σε ένα κοινό σύστημα καθιστά τα CPS ιδιαίτερα κατάλληλα για εφαρμογές
που απαιτούν χαμηλή καθυστέρηση, αξιοπιστία και αυτονομία. Όπως προαναφέρθηκε,
στο πεδίο της γεωργίας ακριβείας, τα CPS διαδραματίζουν καθοριστικό ρόλο, καθώς
συνδυάζουν αισθητήρες πεδίου, μηχανισμούς ελέγχου άρδευσης, και αλγορίθμους
πρόβλεψης βασισμένους σε δεδομένα για να εξασφαλίσουν βέλτιστες συνθήκες
καλλιέργειας. Οι τεχνολογίες αυτές επιτρέπουν τη δυναμική λήψη αποφάσεων,
μειώνουν τις απώλειες και αυξάνουν την αποδοτικότητα σε όλα τα στάδια της
παραγωγής.

\section{Kafka}

Για να επιτευχθεί όμως η πλήρης δυναμική των CPS, απαιτούνται ισχυρές υποδομές
διασύνδεσης και διαχείρισης δεδομένων. Εδώ εντάσσεται η ανάγκη για αξιόπιστες
messaging πλατφόρμες, όπως το Apache Kafka, που διασφαλίζουν την συνεχή και
αξιόπιστη ροή πληροφοριών ανάμεσα στα υποσυστήματα ενός CPS. Το Apache Kafka
αποτελεί ένα, πλέον, de facto πρότυπο για την υλοποίηση τέτοιων messaging
υποδομών, χάρη στη δυνατότητα του να αποθηκεύει τα μηνύματα σε μορφή καταγραφής
(log-based) \cite{kafkabdd}.

\begin{figure}[htbp]
    \centering
    \makebox[\textwidth]{%
        \includegraphics[width=1\textwidth]{kafka-prod-cons.png}
    }
    \caption{Αρχιτεκτονική Apache Kafka: Ροή μηνυμάτων από τους producers στους
    consumers μέσω των topics του broker \cite{RedHatKafka}.}
    \label{fig:kafka_arch}
\end{figure}

Η αρχιτεκτονική του Kafka ενδείκνυται ιδιαίτερα
για περιβάλλοντα που απαιτούν real ή near-real time επεξεργασία γεγονότων,
καθώς παρέχει υψηλή διαθεσιμότητα, εγγυημένη διανομή μηνυμάτων και δυνατότητα
οριζόντιας κλιμάκωσης. Συγκριτικές μελέτες \cite{rtkafka} επιβεβαιώνουν ότι το
Kafka παρουσιάζει σημαντικό πλεονέκτημα σε όρους throughput και fault tolerance
σε σχέση με άλλες προσεγγίσεις, γεγονός που το καθιστά κατάλληλο για
απαιτητικές IoT εφαρμογές με αυξημένο όγκο και ταχύτητα δεδομένων.

Σε ένα κατανεμημένο σύστημα επεξεργασίας δεδομένων μεγάλης κλίμακας, όπου η ροή
των δεδομένων είναι αδιάκοπη και εξελίσσεται σε πραγματικό χρόνο, η ταχεία
εισαγωγή και εξαγωγή των δεδομένων εκτιμάται, τόσο για λόγους απόδοσης όσο και
για την ελαχιστοποίηση της κατανάλωσης υπολογιστικών πόρων. Δοθέντος ενός
συνόλου αισθητήρων τοποθετημένων σε έναν αγρό, οι οποίοι παράγουν συνεχώς
δεδομένα, ο κεντρικός broker πρέπει να τα λαμβάνει ορθά και εντός λογικών
χρονικών πλαισίων, ενώ ταυτόχρονα να τα επεξεργάζεται χωρίς να καταπονεί το
συνολικό σύστημα. Συνεπώς, πρέπει να ληφθούν υπόψη τόσο η ποιότητα υπηρεσίας
(Quality of Service - QoS) της messaging υποδομής όσο και οι εγγυήσεις
παράδοσης που αυτή προσφέρει. Στη συγκεκριμένη εφαρμογή, η απώλεια ενός
μεμονωμένου δείγματος αισθητήρα δεν επηρεάζει σημαντικά τη συνολική ανάλυση,
επομένως η πολιτική "\textbf{at-least-once}" αποτελεί μια ασφαλή και επαρκή
επιλογή. Οι Kreps et al. \cite{kafkaoriginal} προσθέτουν, πως το Kafka
σχεδιάστηκε εξαρχής με γνώμονα το υψηλό throughput, αποφεύγοντας περίπλοκους
μηχανισμούς όπως το two-phase commit και υιοθετώντας πιο αποδοτικές λύσεις για
περιπτώσεις όπου η απώλεια μηνυμάτων είναι αποδεκτή.

Τα δεδομένα που εισάγονται στα topics του \textit{Kafka} επεξεργάζονται και
καταλήγουν είτε σε επόμενα topics για μετέπειτα ανάλυση, είτε απευθείας σε
αποθηκευτικά συστήματα. Ο τρόπος με τον οποίο πραγματοποιείται η εν λόγω
επεξεργασία οφείλει να είναι, εν γένει, σε πραγματικό ή σχεδόν πραγματικό
χρόνο, καθώς τα δεδομένα παράγονται και εισάγονται στο σύστημα σε συνθήκες
online ροής. Επομένως, εργαλεία όπως το \textit{Apache Flink}, τα οποία
παρέχουν native υποστήριξη για stream processing με χαμηλή καθυστέρηση,
καθίστανται ιδανικά για την υλοποίηση του ενδιάμεσου επιπέδου επεξεργασίας.

\section{Stream Processing}

Η επεξεργασία ροών δεδομένων σε πραγματικό χρόνο απαιτεί συστήματα που μπορούν
να διαχειριστούν συνεχείς ροές δεδομένων, να υποστηρίζουν stateful processing
και να διασφαλίζουν αξιοπιστία ακόμη και σε περιπτώσεις προσωρινών αποτυχιών.
Στην ενότητα αυτή παρουσιάζονται τα συστήματα \textit{Flink} και
\textit{Arroyo}, με έμφαση στη λειτουργικότητα, την αρχιτεκτονική και την
καταλληλότητά τους για CPS πραγματικού χρόνου και IoT pipelines.

\subsection{Flink}

Το \textit{Flink} επιτρέπει τον ορισμό παραθύρων (windows) με βάση τον χρόνο
γεγονότος (event time), την υλοποίηση πολύπλοκων λειτουργιών (όπως filtering,
aggregation, enrichment), καθώς και την ενσωμάτωση με messaging και
αποθηκευτικά συστήματα, μεταξώ των οποίων και το \textit{Apache Kafka} και το
\textit{Apache Cassandra}. Επιπλέον, μέσω του μηχανισμού state management που
διαθέτει, διασφαλίζεται η αξιοπιστία της επεξεργασίας, ακόμη και σε περιπτώσεις
προσωρινών αποτυχιών. Η ενσωμάτωση του σε αρχιτεκτονικές τύπου CPS επιτρέπει τη
δημιουργία πραγματικά αντιδραστικών συστημάτων, τα οποία μπορούν να λαμβάνουν
αποφάσεις βάσει εξελισσόμενων δεδομένων, χωρίς να απαιτείται off-line
επεξεργασία ή χρονική υστέρηση.

\subsection{Arroyo}

Παρά το γεγονός ότι το \textit{Apache Flink} αποτελεί μια ώριμη και πλήρως
εξοπλισμένη λύση για την επεξεργασία ροών δεδομένων, η υψηλή πολυπλοκότητα και
οι λειτουργικές απαιτήσεις του περιβάλλοντος JVM κρίθηκαν υπερβολικές για τις
ανάγκες της παρούσας αρχιτεκτονικής. Για τον λόγο αυτόν επιλέχθηκε το
\textit{Arroyo}, ένα \textit{open-source} σύστημα επεξεργασίας ροών (stream
processing) γραμμένο σε \textit{Rust}.

\begin{figure}[htbp]
    \centering
    \makebox[\textwidth]{%
	\includegraphics[width=0.65\textwidth]{arroyo_arch.png}
    }
    \caption{Εσωτερική αρχιτεκτονική του Arroyo: Διαχωρισμός control plane και
    data plane με χρήση workers \cite{ArroyoArch}.}
    \label{fig:arroyo_arch}
\end{figure}

Το \textit{Arroyo}, αν και δεν υποστηρίζει ακόμα όλες τις δυνατότητες του
\textit{Flink}, καλύπτει επαρκώς τις απαιτήσεις της αρχιτεκτονικής της
προτεινόμενης πλατφόρμας για \textit{real-time} επεξεργασία και
\textit{event-driven pipelines}. Λόγω της τρέχουσας μορφής του, δεν διαθέτει
native connectors για βάσεις δεδομένων όπως η \textit{Cassandra}, γι’ αυτό
υλοποιήθηκε μια \textbf{custom διασύνδεση} που επιτρέπει την απρόσκοπτη
ενσωμάτωση στο υπόλοιπο οικοσύστημα της υποδομής, χωρίς να επηρεάζεται η
αξιοπιστία ή η απόδοση των pipelines.

Η χρήση της \textit{Rust} εξασφαλίζει μεγαλύτερη ασφάλεια μνήμης, σταθερότερο
concurrency model και χαμηλότερο latency, στοιχεία κρίσιμα για CPS πραγματικού
χρόνου. Επιπλέον, η αρχιτεκτονική του επιτρέπει εύκολη κλιμάκωση, stateful
processing και ενσωμάτωση με custom stream sources και sinks, γεγονός που το
καθιστά κατάλληλο για πειραματικά και ερευνητικά περιβάλλοντα CPS, ενώ
παραμένει μια υπό παρακολούθηση λύση για πιθανή μελλοντική χρήση σε παραγωγικά
συστήματα, όταν οι δυνατότητές του επεκταθούν.

Αυτό το μοντέλο προσφέρει έναν ευέλικτο, \textit{lightweight} και υψηλής
απόδοσης μηχανισμό επεξεργασίας ροών, με χαμηλή πολυπλοκότητα ανάπτυξης και
συντήρησης, χωρίς τις καθυστερήσεις και την πολυπλοκότητα που φέρνει το
\textit{JVM-based Flink}.

\section{Distributed Storage}

Η αποθήκευση μεγάλου όγκου δεδομένων σε κατανεμημένα συστήματα απαιτεί
συστήματα που μπορούν να διαχειριστούν write-heavy workloads με υψηλή
διαθεσιμότητα και επεκτασιμότητα. Τα wide-column databases αποτελούν την κύρια
επιλογή σε τέτοια σενάρια, προσφέροντας replication, partitioning και
δυνατότητες eventual consistency, απαραίτητες για εφαρμογές πραγματικού χρόνου
και streaming δεδομένων IoT. Στην ενότητα αυτή αναλύονται τα συστήματα
\textit{Cassandra} και \textit{ScyllaDB}, παρουσιάζοντας τα χαρακτηριστικά
τους, τα πλεονεκτήματα και την καταλληλότητά τους για workloads με υψηλή
συχνότητα εγγραφών και απαιτήσεις χαμηλού latency.

\subsection{Cassandra}

Η Cassandra ακολουθεί το μοντέλο \textit{eventual consistency}, υποστηρίζει
κατανεμημένη αποθήκευση με replication και partitioning, και έχει σχεδιαστεί
για εφαρμογές συχνής καταχώρησης και αποθήκευσης (write-heavy)
\cite{cassandrawp}. Σε περιβάλλοντα IoT, όπου οι συσκευές παράγουν συνεχώς
δεδομένα τηλεμετρίας (π.χ. θερμοκρασία, τάση, ρεύμα) με υψηλή συχνότητα, η
Cassandra μπορεί να λειτουργήσει ως backend αποθήκευσης για ροές δεδομένων
σχεδόν σε πραγματικό χρόνο, διασφαλίζοντας υψηλή διαθεσιμότητα και συνεχή
εγγραφή με χαμηλό latency. Η προσέγγιση αυτή έχει εφαρμοστεί επιτυχώς σε
σενάρια όπως η παρακολούθηση φωτοβολταϊκών μονάδων μέσω Raspberry Pi
\cite{iotcassandra}, όπου το σύστημα συλλέγει και αποθηκεύει μετρήσεις
αισθητήρων κάθε 15 λεπτά για περαιτέρω ανάλυση και βελτιστοποίηση απόδοσης.
Αντίστοιχες αρχιτεκτονικές υποδεικνύουν τη σημασία της επιλογής αποθηκευτικού
συστήματος που να ανταποκρίνεται τόσο σε επιχειρησιακές ανάγκες χαμηλής
καθυστέρησης όσο και σε απαιτήσεις αξιοπιστίας και επεκτασιμότητας.

Στη συγκεκριμένη περίπτωση, η υψηλή απόδοση (high performance) της
\textit{Cassandra} σε συνδυασμό με την εύκολη και ελαστική επεκτασιμότητα
(elastic scalability), καθιστά το σύστημα ιδανικό για εφαρμογές πραγματικού
χρόνου με έντονη ροή δεδομένων. Η δυνατότητα προσθήκης ή αφαίρεσης κόμβων
(nodes) χωρίς διακοπή λειτουργίας επιτρέπει την ομαλή προσαρμογή στις
αυξομειώσεις φορτίου, επιτρέπωντας το self-healing, διατηρώντας παράλληλα
σταθερή τη χρονική απόκριση. Καθώς το σύστημα απαιτεί ταχεία επεξεργασία, άμεση
καταχώρηση και αξιόπιστη αποθήκευση δεδομένων αισθητήρων πεδίου, η επιλογή μιας
αρχιτεκτονικής βασισμένης στην \textit{Cassandra} εξασφαλίζει υψηλή
διαθεσιμότητα και ανθεκτικότητα σε αποτυχία. Το λειτουργικό όφελος που
προκύπτει από αυτήν τη σχεδίαση δεν είναι απλώς επιθυμητό αλλά κρίσιμης
σημασίας, ιδιαίτερα σε περιβάλλοντα με απαιτήσεις χαμηλού latency, συνεχούς
διαθεσιμότητας και γραμμικής επεκτασιμότητας.

\subsection{ScyllaDB}

Παρά την ωριμότητα και τη διαδεδομένη χρήση της \textit{Cassandra}, για την
κάλυψη των αναγκών του συγκεκριμένου συστήματος επιλέχθηκε να χρησιμοποιηθεί η
\textit{ScyllaDB}, ένα σύστημα wide-column σχεδιασμένο ως drop-in
αντικαταστάτης της Cassandra, αλλά με σημαντικά βελτιωμένα χαρακτηριστικά
απόδοσης και χαμηλότερο latency. Η ScyllaDB είναι γραμμένη σε \textit{C++} και
χρησιμοποιεί ένα πλήρως ασύγχρονο, \textit{shard-per-core} αρχιτεκτονικό
μοντέλο, εκμεταλλευόμενη πλήρως τις δυνατότητες των πολυπύρηνων επεξεργαστών,
μειώνοντας την καθυστέρηση του \textit{JVM} που χαρακτηρίζει την
\textit{Cassandra}.

H \textit{ScyllaDB} υποστηρίζει \textit{replication}, \textit{partitioning} και
\textit{eventual consistency} με δυνατότητα \textit{fine-tuned consistency
levels}, επιτρέποντας τον ακριβή έλεγχο μεταξύ latency και αξιοπιστίας, ανάλογα
με τις ανάγκες κάθε \textit{pipeline}. Η υποστήριξη \textit{date bucketing} και
\textit{time-series optimized tables} καθιστά τη \textit{ScyllaDB} ιδανική για
ροές τηλεμετρίας IoT, όπου τα δεδομένα γράφονται συνεχώς και προσπελάζονται
τόσο για dashboards πραγματικού χρόνου όσο και για ιστορικές αναλύσεις.

\begin{figure}[htbp]
    \centering
    \makebox[\textwidth]{%
	\includegraphics[width=\textwidth]{scylladb.png}
    }
    \caption{Αρχιτεκτονική ScyllaDB: H Shard-per-core επεξεργασία και η διαδρομή
    δεδομένων από τη μνήμη (Memtable) στον δίσκο (SSTables) \cite{ScyllaDBArch}.}
    \label{fig:scylladb}
\end{figure}

Σε σύγκριση με την \textit{Cassandra}, η \textit{ScyllaDB} παρέχει:

\begin{itemize}
	\item \textbf{Χαμηλότερο latency:} χάρη στο ασύγχρονο,
		\textit{shard-per-core} μοντέλο που μειώνει το \textit{lock
		contention} αλλά και τις καθυστερήσεις λόγω \textit{garbage
		collection}.
	\item \textbf{Πλήρη αξιοποίηση multi-core:} κάθε πυρήνας του
		επεξεργαστή διαχειρίζεται ένα \textit{shard}, επιτρέποντας
		γραμμική κλιμάκωση με την προσθήκη κόμβων.
	\item \textbf{Προβλέψιμη απόδοση:} μειωμένη διακύμανση στην καθυστέρηση
		ακόμα και σε \textit{write-heavy} διεργασίες.
	\item \textbf{Time-series friendly:} εύκολη εφαρμογή \textit{date bucketing} και
		\textit{retention policies} για μακροχρόνια αποθήκευση μεγάλου όγκου
		δεδομένων.
\end{itemize}

Η επιλογή της \textit{ScyllaDB} επιτρέπει άμεση καταχώρηση μεγάλου όγκου
τηλεμετρίας από αισθητήρες με συνεχείς ροές δεδομένων, εξασφαλίζοντας παράλληλα
την ανάγνωση σε πραγματικό χρόνο για ανάλυση ή \textit{triggers} επεξεργασίας
σε \textit{stream processing pipelines} όπως το \textit{Arroyo}. Η δυνατότητα
εύκολης κλιμάκωσης και \textit{self-healing} κόμβων επιτρέπει στο σύστημα να
προσαρμόζεται δυναμικά σε αυξομειώσεις φορτίου, ενώ η υψηλή αξιοπιστία και η
χαμηλή καθυστέρηση το καθιστούν προτιμητέα επιλογή για παραγωγικά \textit{CPS}
περιβάλλοντα σε σύγκριση με την Cassandra.

Με αυτήν την επιλογή, η πλατφόρμα εκμεταλλεύεται τις βελτιώσεις της
\textit{ScyllaDB} σε \textit{throughput} και προβλεψιμότητα, χωρίς να θυσιάζει
την ευελιξία και τη διαλειτουργικότητα που απαιτούνται για εφαρμογές
\textit{IoT} πραγματικού χρόνου και \textit{CPS}.

\section{Caching}

Η προσωρινή αποθήκευση (caching) αποτελεί κρίσιμο στοιχείο σε CPS και
κατανεμημένες υποδομές, όπου η συνεχής εισροή δεδομένων απαιτεί γρήγορη και
αξιόπιστη προσπέλαση για εφαρμογές πραγματικού χρόνου. Ο κύριος στόχος των
μηχανισμών \textit{caching} είναι η μείωση του \textit{latency} και η
αποσυμφόρηση των βάσεων δεδομένων, επιτρέποντας την άμεση παροχή δεδομένων
στους χρήστες ή στις υπηρεσίες ανάλυσης. Μέσω \textit{caching}, οι εφαρμογές
διεπαφής μπορούν να παρέχουν οπτικοποιημένη και άμεσα αξιοποιήσιμη πληροφόρηση
χωρίς να επηρεάζεται η απόδοση του \textit{backend} ή η συνολική επεκτασιμότητα
του συστήματος.

Στην ενότητα αυτή αναλύονται οι κύριες τεχνολογίες \textit{in-memory caching}
που εξετάστηκαν, με έμφαση στα χαρακτηριστικά τους, τα πλεονεκτήματα, τις
αρχιτεκτονικές επιλογές και την καταλληλότητά τους για εργασίες πραγματικού
χρόνου. Οι υποενότητες καλύπτουν τις λύσεις \textit{Redis}, \textit{Valkey},
\textit{DragonflyDB} και \textit{Memcached}, προσφέροντας συγκριτική θεώρηση
και επιχειρήματα για την τελική επιλογή.

\subsection{Redis}

Το \textit{Redis} αποτελεί ένα από τα πιο δημοφιλή συστήματα \textit{in-memory
key-value stores}, προσφέροντας γρήγορη προσπέλαση σε δεδομένα με χαμηλή
καθυστέρηση και υποστήριξη σύνθετων data structures όπως \textit{lists, sets,
sorted sets} και \textit{hashes}. Η αρχιτεκτονική του βασίζεται σε μοντέλο
\textit{event loop}, το οποίο εξασφαλίζει αποτελεσματική διαχείριση ταυτόχρονων
αιτημάτων χωρίς τις καθυστερήσεις του \textit{multithreading}. Επιπλέον, το
\textit{Redis} προσφέρει δυνατότητες persistence, replication και pub/sub
messaging, γεγονός που το καθιστά κατάλληλο για εφαρμογές πραγματικού χρόνου
όπου απαιτείται υψηλή ταχύτητα ανάγνωσης και εγγραφής.

\begin{figure}[htbp]
    \centering
    \makebox[\textwidth]{%
	\includegraphics[width=\textwidth]{redis-cluster.png}
    }
    \caption{Αρχιτεκτονική Master-Slave Replication: Απεικόνιση της ροής
	    δεδομένων από τον Master κόμβο προς τους Slaves. Ο μηχανισμός αυτός
	    επιτρέπει την ανάγνωση από πολλαπλούς κόμβους (read scalability)
	    και την παροχή αντιγράφων ασφαλείας σε πραγματικό χρόνο \cite{StackademicRedis}.}
    \label{fig:redis_replication}
\end{figure}

Η αρχιτεκτονική που απεικονίζεται στο Σχήμα~\ref{fig:redis_replication}
αποτελεί τη βάση για τη διασφάλιση της ανθεκτικότητας (durability) και της
διαθεσιμότητας (availability). Η χρήση \textit{Master-Slave replication}
επιτρέπει την αυτόματη ανάκαμψη (failover) σε περίπτωση αστοχίας, καθώς ένας εκ
των Slaves μπορεί να προαχθεί σε Master, ενώ η παράλληλη χρήση μηχανισμών
\textit{persistence to disk} εγγυάται την ακεραιότητα των δεδομένων μετά από
επανεκκίνηση.

\subsection{Valkey}

Με την προσωρινή μετατροπή του \textit{Redis} σε κλειστό λογισμικό, εμφανίστηκε
η ανάγκη για μια ανοικτή, και υποστηριζόμενη από την κοινότητα, εναλλακτική. Το
\textit{Valkey} προέκυψε ως φυσική συνέχεια του \textit{Redis} υπό την αιγίδα
του \textit{Linux Foundation}, διατηρώντας συμβατότητα με το \textit{API} του
\textit{Redis} αλλά ως πλήρως ανοιχτό λογισμικό. Μιας και η υποστήριξη
μακροπρόθεσμης συντήρησης και η διαλειτουργικότητα είναι κρίσιμες ζητούμενα, το
\textit{Valkey} παρέχει ένα ασφαλές και αξιόπιστο πυλώνα για \textit{caching}
και πρόσβαση δεδομένων σε πραγματικό χρόνο.

\subsection{DragonflyDB}

Το \textit{DragonflyDB} αποτελεί μια σύγχρονη, \textit{Redis-compatible} υλοποίηση,
σχεδιασμένη ως \textit{drop-in} αντικαταστάτης, προσφέροντας ταχύτερη εκκίνηση και
βελτιστοποιημένη διαχείριση μνήμης. Αν και χρήσιμο για γρήγορα tests ή
περιβάλλοντα ανάπτυξης, η εμπειρία σε παραγωγικές διαδικασίες έδειξε ότι, για
συνεχή, υψηλό throughput και εγγυημένη διαθεσιμότητα, η επιλογή Valkey
παραμένει προτιμητέα. Η δυνατότητα seamless μετακίνησης μεταξύ Redis,
DragonflyDB και Valkey προσφέρει ευελιξία, χωρίς να δεσμεύει τη μακροπρόθεσμη
στρατηγική του συστήματος.

\subsection{Memcached}

Παρά την κυριαρχία των λύσεων βασισμένων στο \textit{Redis}, το
\textit{Memcached} παραμένει μια ελαφριά και δοκιμασμένη τεχνολογία για caching
απλών ζεύγων κλειδιού-τιμής, με πολυνηματική αρχιτεκτονική που επιτρέπει την
αποτελεσματική αξιοποίηση πολλαπλών πυρήνων CPU. Η απλότητα και η σταθερότητα
του \textit{Memcached} το καθιστούν ιδανικό για σενάρια όπου απαιτείται
αποκλειστικά γρήγορη προσωρινή αποθήκευση χωρίς σύνθετες δομές δεδομένων ή
persistence, διατηρώντας χαμηλό footprint και προβλέψιμη σταθερότητα στην
απόδοση σε write-heavy workloads.

\section{Kubernetes}

Η ανάγκη για παρατηρησιμότητα, αποδοτική διαχείριση προσωρινών δεδομένων και
σταθερή ροή μηνυμάτων σε περιβάλλοντα με κατανεμημένη υπολογιστική λογική,
καθιστά την πλατφόρμα \textit{Kubernetes}, συχνά, απαραίτητο δομικό στοιχείο. Η
δυνατότητα αυτόματης επανεκκίνησης αποτυχημένω πόρων (self-healing), η
υποστήριξη οριζόντιας κλιμάκωσης (horizontal pod autoscaling) και η
ενσωματωμένη παρακολούθηση της κατάστασης των υπηρεσιών (liveness/readiness
probes), προσδίδουν λειτουργική ανθεκτικότητα και διατηρούν τη διαθεσιμότητα
του συστήματος σε υψηλά επίπεδα, ακόμη και σε συνθήκες έντονου φορτίου ή υλικών
αποτυχιών.

\begin{figure}[htbp]
    \centering
    \makebox[\textwidth]{%
	\includegraphics[width=\textwidth]{kubernetes-autoscaling.png}
    }
    \caption{Μηχανισμοί Autoscaling στο Kubernetes: Απεικόνιση της
	    αλληλεπίδρασης μεταξύ του Horizontal Pod Autoscaler (HPA), του
	    Cluster Autoscaler και των pods για τη διαχείριση μεταβαλλόμενων
	    υπολογιστικών αναγκών. Προσαρμογή από \cite{ZestyK8s}.}
    \label{fig:k8s_autoscaling}
\end{figure}

Όπως φαίνεται στο Σχήμα~\ref{fig:k8s_autoscaling}, η χρήση του
\textit{Horizontal Pod Autoscaler} επιτρέπει την αυξομείωση των \textit{pods}
βάσει μετρικών (όπως CPU ή RAM), ενώ ο \textit{Cluster Autoscaler} διασφαλίζει
ότι υπάρχουν αρκετοί φυσικοί πόροι (Nodes) για να φιλοξενήσουν τα νέα
\textit{pods}. Αυτοί οι μηχανισμοί, σε συνδυασμό με τα
\textit{liveness/readiness probes}, προσδίδουν λειτουργική ανθεκτικότητα και
διατηρούν τη διαθεσιμότητα του συστήματος σε υψηλά επίπεδα.

Πέραν της αυτοματοποιημένης διαχείρισης πόρων, το \textit{Kubernetes} παρέχει
μια ενιαία πλατφόρμα παρατηρησιμότητας. Μέσω της ενσωμάτωσης εργαλείων όπως το
\textit{Prometheus} για συλλογή μετρικών, το \textit{Grafana} για οπτικοποίηση
και το \textit{AlertManager} για την αποστολή ειδοποιήσεων, \cite{inframon} -
κοινώς τη \textbf{lingua franca} του \textit{observability} - ενισχύεται η
κατανόηση της δυναμικής συμπεριφοράς του συστήματος σε πραγματικό χρόνο. Η
εγγενής υποστήριξη μηχανισμών για service discovery, load balancing και
declarative configuration, επιτρέπει την ευέλικτη ανάπτυξη και τον συντονισμό
μικροϋπηρεσιών, διευκολύνοντας την επίτευξη στόχων υψηλής διαθεσιμότητας και
επεκτασιμότητας σε cloud-native περιβάλλοντα. Συνεπώς, υιοθετώντας αντίστοιχα
πρότυπα, μπορούν να προληφθούν ανεπιθύμητες καταστάσεις και να διασφαλιστεί η
διατήρηση της ομαλής λειτουργίας ακόμα και υπο συνθήκες υψηλής πολυπλοκότητας.
